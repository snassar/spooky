# Spooky Project Cursor Rules

## Project Overview
Spooky is an SSH automation tool written in Go that executes commands and scripts on multiple remote servers using HCL2 configuration files. It aims to be a lightweight alternative to Ansible with declarative configuration and parallel execution capabilities.

## Core Technologies & Dependencies
- **Go 1.24+**: Minimum required version for all builds, tests, and documentation
- **HCL2**: Configuration language (github.com/hashicorp/hcl/v2)
- **Cobra**: CLI framework (github.com/spf13/cobra)
- **SSH**: golang.org/x/crypto/ssh for SSH client operations
- **Validator**: github.com/go-playground/validator/v10 for configuration validation
- **gliderlabs/ssh**: For integration testing mock SSH servers

## Code Organization & Structure

### Directory Structure
```
spooky/
├── internal/           # Core application code
│   ├── config/        # Configuration parsing and validation
│   └── ssh/           # SSH client and execution logic
├── tests/             # Integration tests and infrastructure
│   ├── infrastructure/ # Mock SSH servers for testing
│   └── helpers.go     # Test utilities
├── examples/          # Example configurations and scripts
├── tools/             # Development tools and utilities
├── docs/              # Documentation
└── main.go           # Application entry point
```

### File Naming Conventions
- **Test Files**: Use `filename_test.go` pattern consistently (e.g., `config_test.go`, `parser_test.go`)
- **Configuration Files**: Use descriptive names: `example.hcl`, `large-scale-example.hcl`
- **Documentation**: Use kebab-case: `TROUBLESHOOTING.md`, `CONTRIBUTING.md`
- **Tools**: Use kebab-case for tool directories: `pre-commit/`, `generate-config/`, `spooky-test-env/`

## Coding Standards

### Go Conventions
- Use `gofmt` for code formatting
- Follow Go naming conventions (camelCase for variables, PascalCase for exported)
- Use meaningful variable and function names
- Add comments for complex logic
- Use `golangci-lint` for code quality checks

### Error Handling
- Use `fmt.Errorf` with `%w` verb for error wrapping
- Return errors from functions, don't panic
- Provide meaningful error messages
- Use `errors.Is` and `errors.As` for error checking

### Testing
- Write unit tests for all exported functions
- Use table-driven tests for multiple scenarios
- Mock external dependencies
- Aim for high test coverage (minimum 80%)
- Use descriptive test names and clear assertions
- Test both positive and negative scenarios

## Configuration & Validation

### HCL2 Configuration Structure
```hcl
# Server definitions
server "server-name" {
  host     = "192.168.1.100"
  port     = 22
  user     = "admin"
  password = "secret"  # or key_file = "~/.ssh/id_ed25519"
  tags = {
    environment = "production"
    datacenter  = "FRA00"
  }
}

# Action definitions
action "update-system" {
  description = "Update system packages"
  command     = "apt update && apt upgrade -y"
  servers     = ["server1", "server2"]
  tags        = ["debian", "production"]
  timeout     = 300
  parallel    = true
}
```

### Validation Rules
- Server names must be unique
- Action names must be unique
- Servers must have either password or key_file (not both or neither)
- Actions must have either command or script (not both or neither)
- Use struct-level validation with go-playground/validator

## CLI Design

### Command Structure
- Use Cobra for CLI framework
- Support both positional arguments and flags
- Provide clear error messages and usage examples
- Use consistent flag naming across commands

### Available Commands
- `spooky execute [config-file]`: Execute actions from configuration
- `spooky validate [config-file]`: Validate configuration syntax
- `spooky list [config-file]`: List servers and actions

### Flag Conventions
- Use long-form flags for cross-platform compatibility
- Provide short aliases for common flags
- Set sensible defaults for timeout and parallel execution
- Use descriptive flag names and help text

## Build & Development

### Makefile Targets
- `make build`: Build the spooky binary
- `make test`: Run all tests with coverage checks
- `make test-unit`: Run unit tests only
- `make test-integration`: Run integration tests only
- `make check-coverage`: Verify coverage thresholds
- `make coverage-html`: Generate HTML coverage report
- `make clean`: Clean build artifacts
- `make fmt`: Format code with gofmt
- `make lint`: Run linter checks

### Development Tools
- **Coverage Tool**: github.com/vladopajic/go-test-coverage/v2 (dev-only dependency)
- **Pre-commit Hook**: Custom Go tool in `tools/pre-commit/` with `pre-commit_test.go`
- **Configuration Generator**: Tool in `tools/generate-config/` with `generate-config_test.go`
- **Test Environment**: Tool in `tools/spooky-test-env/` with `spooky-test-env_test.go`
- **Linter**: golangci-lint for code quality checks
- **Mock SSH**: gliderlabs/ssh for integration testing

### Pre-commit Requirements
- All commits must pass coverage thresholds
- Code must be formatted with gofmt
- Tests must pass (unit and integration)
- Use `git commit --no-verify` only for emergency fixes

## Documentation Standards

### README Requirements
- Clear installation and usage instructions
- Example configuration files
- Test coverage badge and requirements
- Contributing guidelines
- License information

### Code Documentation
- Add descriptive comments for complex logic
- Document exported functions and types
- Include examples for new features
- Update documentation when adding new functionality

### Issue Templates
- Use markdown format for all documentation
- Include code examples and configuration snippets
- Provide troubleshooting steps for common issues
- Reference related documentation and examples

## Security Considerations

### SSH Security
- Only support Ed25519 keys (no RSA or DSA)
- Validate SSH key formats and permissions
- Use secure defaults for timeouts and connection limits
- Implement proper error handling for authentication failures

### Configuration Security
- Don't log sensitive information (passwords, keys)
- Validate configuration file permissions
- Use environment variables for sensitive data when possible
- Implement proper input validation for all configuration fields

## Performance & Scalability

### Large-Scale Deployments
- Support for parallel execution across multiple servers
- Configurable timeouts to prevent hanging connections
- Efficient SSH connection pooling
- Tag-based targeting for flexible server grouping

### Resource Management
- Limit concurrent connections to prevent resource exhaustion
- Implement connection timeouts
- Use connection pooling where appropriate
- Monitor memory usage during large operations

## Testing Strategy

### Unit Tests
- Test individual functions and methods
- Mock external dependencies (SSH, file system)
- Use table-driven tests for multiple scenarios
- Aim for 80%+ coverage on core functionality

### Integration Tests
- Test end-to-end workflows
- Use mock SSH servers for realistic testing
- Test configuration parsing and validation
- Verify CLI command behavior

### Test Environment
- Use Podman containers for isolated testing
- Mock SSH servers for reliable test execution
- Automated test environment setup and teardown
- Consistent test data and configurations

## Deployment & Distribution

### Build Process
- Cross-platform builds (Linux, macOS, Windows)
- Statically linked binaries where possible
- Version information embedded in binaries
- Automated release process

### Distribution
- GitHub releases with pre-built binaries
- Docker images for containerized deployment
- Package managers (Homebrew, apt, etc.)
- Clear installation instructions

## Contributing Guidelines

### Code Review Process
- All changes require pull request review
- Automated tests must pass
- Code coverage must meet minimum thresholds
- Documentation must be updated for new features

### Development Workflow
- Feature branches from main
- Descriptive commit messages
- Squash commits before merging
- Update CHANGELOG.md for user-facing changes

### Issue Reporting
- Use GitHub issues for bug reports and feature requests
- Include reproduction steps for bugs
- Provide system information and error logs
- Tag issues appropriately (bug, enhancement, documentation) 